/*
 * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License").
 * http://aws.amazon.com/apache2.0/
 */
package ch.zhaw.deeplearningjava.reptile;

import java.io.IOException;
import java.nio.file.Path;
import java.nio.file.Paths;

import ai.djl.Model;
import ai.djl.basicdataset.cv.classification.ImageFolder;
import ai.djl.basicmodelzoo.cv.classification.ResNetV1;
import ai.djl.metric.Metrics;
import ai.djl.modality.cv.transform.Resize;
import ai.djl.modality.cv.transform.ToTensor;
import ai.djl.ndarray.types.Shape;
import ai.djl.nn.Block;
import ai.djl.training.DefaultTrainingConfig;
import ai.djl.training.EasyTrain;
import ai.djl.training.Trainer;
import ai.djl.training.TrainingConfig;
import ai.djl.training.TrainingResult;
import ai.djl.training.dataset.RandomAccessDataset;
import ai.djl.training.evaluator.Accuracy;
import ai.djl.training.listener.TrainingListener;
import ai.djl.training.loss.Loss;
import ai.djl.translate.TranslateException;

/**
 * ğŸ‡¬ğŸ‡§ Trains a classification model using DJL and saves the resulting model for inference.
 * ğŸ‡«ğŸ‡· EntraÃ®ne un modÃ¨le de classification avec DJL et le sauvegarde pour l'infÃ©rence.
 * ğŸ‡©ğŸ‡ª Trainiert ein Klassifikationsmodell mit DJL und speichert es fÃ¼r spÃ¤tere Verwendung.
 */
public final class Training {

    private static final int BATCH_SIZE = 32;   // Taille du lot (Batch size)
    private static final int EPOCHS = 10;       // Nombre d'itÃ©rations complÃ¨tes sur le dataset

    public static void main(String[] args) throws IOException, TranslateException {

        // ğŸ“ RÃ©pertoire de sauvegarde du modÃ¨le entraÃ®nÃ©
        Path modelDir = Paths.get("src/main/resources/models");

        // ğŸ“‚ Chargement du dataset d'entraÃ®nement (ex: lizard, snake, salamander)
        ImageFolder dataset = initDataset("src/main/resources/dataset");
        RandomAccessDataset[] datasets = dataset.randomSplit(8, 2); // 80% train / 20% val

        // âš™ï¸ Configuration de l'entraÃ®nement avec fonction de perte et accuracy
        Loss loss = Loss.softmaxCrossEntropyLoss();
        TrainingConfig config = setupTrainingConfig(loss);

        // ğŸ§  CrÃ©ation dynamique du modÃ¨le avec nombre de classes correct
        Model model = Models.getModel();
        int numClasses = dataset.getSynset().size();  // nombre rÃ©el de classes

        Block resNet = ResNetV1.builder()
                .setImageShape(new Shape(3, Models.IMAGE_HEIGHT, Models.IMAGE_WIDTH))
                .setNumLayers(50)
                .setOutSize(numClasses)
                .build();

        model.setBlock(resNet);

        // ğŸ¯ Initialisation du trainer
        Trainer trainer = model.newTrainer(config);
        trainer.setMetrics(new Metrics());
        Shape inputShape = new Shape(1, 3, Models.IMAGE_HEIGHT, Models.IMAGE_WIDTH);
        trainer.initialize(inputShape);

        // ğŸš€ EntraÃ®nement du modÃ¨le (10 epochs par dÃ©faut)
        EasyTrain.fit(trainer, EPOCHS, datasets[0], datasets[1]);

        // ğŸ§¾ Sauvegarde des propriÃ©tÃ©s du modÃ¨le
        TrainingResult result = trainer.getTrainingResult();
        model.setProperty("Epoch", String.valueOf(EPOCHS));
        model.setProperty("Accuracy", String.format("%.5f", result.getValidateEvaluation("Accuracy")));
        model.setProperty("Loss", String.format("%.5f", result.getValidateLoss()));

        // ğŸ’¾ Sauvegarde du modÃ¨le et des classes
        model.save(modelDir, Models.MODEL_NAME);
        Models.saveSynset(modelDir, dataset.getSynset());

        System.out.println("âœ… ModÃ¨le entraÃ®nÃ© et sauvegardÃ© avec succÃ¨s.");
    }

    // ğŸ“¥ PrÃ©paration du dataset d'images avec resize + normalisation
    private static ImageFolder initDataset(String datasetRoot) throws IOException, TranslateException {
        ImageFolder dataset = ImageFolder.builder()
                .setRepositoryPath(Paths.get(datasetRoot))
                .optMaxDepth(10)
                .addTransform(new Resize(Models.IMAGE_WIDTH, Models.IMAGE_HEIGHT))
                .addTransform(new ToTensor())
                .setSampling(BATCH_SIZE, true)
                .build();

        dataset.prepare();
        return dataset;
    }

    // âš™ï¸ Configuration DJL avec Loss + Accuracy + logs
    private static TrainingConfig setupTrainingConfig(Loss loss) {
        return new DefaultTrainingConfig(loss)
                .addEvaluator(new Accuracy())
                .addTrainingListeners(TrainingListener.Defaults.logging());

                 }
}
